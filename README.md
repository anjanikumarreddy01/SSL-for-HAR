Applying sensor-based deep learning models in human activity recognition (HAR) requires annotated timeseries data. Still, getting such data is typically time-consuming, costly, and physically demanding. This paper introduces Gated recurrent network and CNN for human activity recognition (CGRNHAR), a new approach meant to address these challenges by employing complex machine learning paradigms, including Contrastive Learning (CL) and Active Learning (AL). CGRNHAR simulates local and global sensory interactions by use of a hybrid encoder architecture including Gated Recurrent Networks (GRNs) and Convolutional Neural Networks (CNNs). By leveraging meaningful feature representations extracted from unlabelled sensor data, CGRNHAR substantially decreases the reliance on annotated datasets. Moreover, contrastive consistency loss (CCLoss) enhances feature discrimination and learning efficiency. Extensive investigations on numerous publicly available HAR datasets reveal that CGRNHAR trumps state-of- the-art self-supervised learning methods especially in conditions with low labelled data or knowledge transfer settings. Its low weight and computationally efficient architecture are appropriate for wearable and mobile devices as well as for environments with restricted resources. This work fills in the void between annotated data dependencies and real-world activity identification by presenting CGRNHAR as a scalable and efficient sensor-based HAR system. By utilizing self-supervised learning, CGRNHAR effectively leverages unlabelled data, thereby enhancing the applicability and relevance of HAR systems in real-world. 
